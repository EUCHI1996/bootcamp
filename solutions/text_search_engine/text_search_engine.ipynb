{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Search Engine\n",
    "In this example we will be going over the code used to build a Text Search Engine. This example uses a modified BERT model to convert text to vectors stored in Milvus, which can then be combined with Milvus to search for similar text to the user input text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "This example uses the English News dataset. In this example, we use a small subset of the dataset containing 180 mutually corresponding title-texts, which can be found in the **Data** directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "\n",
    "|  Packages   |  Servers    |\n",
    "|-                  | -                 |   \n",
    "| pymilvus          | milvus-1.1.0      |\n",
    "| sentence_transformers      | postgres          |\n",
    "| psycopg2          |\n",
    "| pandas           |\n",
    "| numpy   |\n",
    "\n",
    "We have included a `requirements.txt` file in order to easily satisfy the required packages. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up and Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Packages\n",
    "Install the required python packages with `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0525 15:31:44.512681617   27776 backup_poller.cc:132]       Run client channel backup poller: {\"created\":\"@1621927904.512601059\",\"description\":\"pollset_work\",\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":321,\"referenced_errors\":[{\"created\":\"@1621927904.512599092\",\"description\":\"Bad file descriptor\",\"errno\":9,\"file\":\"src/core/lib/iomgr/ev_epollex_linux.cc\",\"file_line\":948,\"os_error\":\"Bad file descriptor\",\"syscall\":\"epoll_wait\"}]}\n",
      "Requirement already satisfied: flask-cors in /data/workspace/minicoda/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (3.0.10)\n",
      "Requirement already satisfied: numpy in /data/workspace/minicoda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.17.4)\n",
      "Requirement already satisfied: flask in /data/workspace/minicoda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: flask_restful in /data/workspace/minicoda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (0.3.9)\n",
      "Requirement already satisfied: pymilvus==1.1.0 in /data/workspace/minicoda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: psycopg2-binary in /data/workspace/minicoda/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (2.8.6)\n",
      "Requirement already satisfied: sentence_transformers in /data/workspace/minicoda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: grpcio-tools>=1.22.0 in /data/workspace/minicoda/lib/python3.7/site-packages (from pymilvus==1.1.0->-r requirements.txt (line 5)) (1.26.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in /data/workspace/minicoda/lib/python3.7/site-packages (from pymilvus==1.1.0->-r requirements.txt (line 5)) (2.0.3)\n",
      "Requirement already satisfied: grpcio>=1.22.0 in /data/workspace/minicoda/lib/python3.7/site-packages (from pymilvus==1.1.0->-r requirements.txt (line 5)) (1.31.0)\n",
      "Requirement already satisfied: requests>=2.22.0 in /data/workspace/minicoda/lib/python3.7/site-packages (from pymilvus==1.1.0->-r requirements.txt (line 5)) (2.25.1)\n",
      "Requirement already satisfied: six>=1.5.2 in /data/workspace/minicoda/lib/python3.7/site-packages (from grpcio>=1.22.0->pymilvus==1.1.0->-r requirements.txt (line 5)) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.5.0.post1 in /data/workspace/minicoda/lib/python3.7/site-packages (from grpcio-tools>=1.22.0->pymilvus==1.1.0->-r requirements.txt (line 5)) (3.13.0)\n",
      "Requirement already satisfied: setuptools in /data/workspace/minicoda/lib/python3.7/site-packages (from protobuf>=3.5.0.post1->grpcio-tools>=1.22.0->pymilvus==1.1.0->-r requirements.txt (line 5)) (51.0.0.post20201207)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /data/workspace/minicoda/lib/python3.7/site-packages (from requests>=2.22.0->pymilvus==1.1.0->-r requirements.txt (line 5)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/workspace/minicoda/lib/python3.7/site-packages (from requests>=2.22.0->pymilvus==1.1.0->-r requirements.txt (line 5)) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /data/workspace/minicoda/lib/python3.7/site-packages (from requests>=2.22.0->pymilvus==1.1.0->-r requirements.txt (line 5)) (1.26.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /data/workspace/minicoda/lib/python3.7/site-packages (from requests>=2.22.0->pymilvus==1.1.0->-r requirements.txt (line 5)) (4.0.0)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in /data/workspace/minicoda/lib/python3.7/site-packages (from flask->-r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /data/workspace/minicoda/lib/python3.7/site-packages (from flask->-r requirements.txt (line 3)) (3.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /data/workspace/minicoda/lib/python3.7/site-packages (from flask->-r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: click>=7.1.2 in /data/workspace/minicoda/lib/python3.7/site-packages (from flask->-r requirements.txt (line 3)) (8.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /data/workspace/minicoda/lib/python3.7/site-packages (from click>=7.1.2->flask->-r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/workspace/minicoda/lib/python3.7/site-packages (from Jinja2>=3.0->flask->-r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: aniso8601>=0.82 in /data/workspace/minicoda/lib/python3.7/site-packages (from flask_restful->-r requirements.txt (line 4)) (9.0.1)\n",
      "Requirement already satisfied: pytz in /data/workspace/minicoda/lib/python3.7/site-packages (from flask_restful->-r requirements.txt (line 4)) (2019.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in /data/workspace/minicoda/lib/python3.7/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (1.8.1)\n",
      "Requirement already satisfied: sentencepiece in /data/workspace/minicoda/lib/python3.7/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (0.1.95)\n",
      "Requirement already satisfied: scikit-learn in /data/workspace/minicoda/lib/python3.7/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (0.24.2)\n",
      "Requirement already satisfied: torchvision in /data/workspace/minicoda/lib/python3.7/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (0.9.1)\n",
      "Requirement already satisfied: scipy in /data/workspace/minicoda/lib/python3.7/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (1.5.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=3.1.0 in /data/workspace/minicoda/lib/python3.7/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (4.6.1)\n",
      "Requirement already satisfied: tqdm in /data/workspace/minicoda/lib/python3.7/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (4.54.1)\n",
      "Requirement already satisfied: nltk in /data/workspace/minicoda/lib/python3.7/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (3.4.5)\n",
      "Requirement already satisfied: typing-extensions in /data/workspace/minicoda/lib/python3.7/site-packages (from torch>=1.6.0->sentence_transformers->-r requirements.txt (line 7)) (3.10.0.0)\n",
      "Requirement already satisfied: filelock in /data/workspace/minicoda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers->-r requirements.txt (line 7)) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /data/workspace/minicoda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers->-r requirements.txt (line 7)) (2021.4.4)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /data/workspace/minicoda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers->-r requirements.txt (line 7)) (0.0.8)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /data/workspace/minicoda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers->-r requirements.txt (line 7)) (0.10.2)\n",
      "Requirement already satisfied: packaging in /data/workspace/minicoda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers->-r requirements.txt (line 7)) (20.8)\n",
      "Requirement already satisfied: sacremoses in /data/workspace/minicoda/lib/python3.7/site-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers->-r requirements.txt (line 7)) (0.0.45)\n",
      "Requirement already satisfied: zipp>=0.5 in /data/workspace/minicoda/lib/python3.7/site-packages (from importlib-metadata->click>=7.1.2->flask->-r requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /data/workspace/minicoda/lib/python3.7/site-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence_transformers->-r requirements.txt (line 7)) (2.4.7)\n",
      "Requirement already satisfied: joblib in /data/workspace/minicoda/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence_transformers->-r requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /data/workspace/minicoda/lib/python3.7/site-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /data/workspace/minicoda/lib/python3.7/site-packages (from torchvision->sentence_transformers->-r requirements.txt (line 7)) (8.0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Milvus Server\n",
    "\n",
    "This demo uses Milvus 1.1.0, please refer to the [Install Milvus](https://milvus.io/docs/v1.1.0/install_milvus.md) guide to learn how to use this docker container. For this example we wont be mapping any local volumes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0ecbc23b01742c348a7af90edb06925bf96e3d3b269a8120b07b3de5ab4cbfff\r\n"
     ]
    }
   ],
   "source": [
    "! docker run --name milvus_cpu_1.1 -d \\\n",
    "-p 19533:19530 \\\n",
    "-p 19123:19121 \\\n",
    "milvusdb/milvus:1.1.0-cpu-d050721-5e559c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Postgres Server\n",
    "For now, Milvus doesn't support storing multiple attributes for the data. Because of this we have to use another service to store these attributes and search through them, in this case PostgreSQL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3623cf3503bae1a2e7a32dddd59862014bfdd09015fb5a74472a14a1b89e07cd\r\n"
     ]
    }
   ],
   "source": [
    "! docker run --name postgres -d  -p 5432:5432 -e POSTGRES_HOST_AUTH_METHOD=trust postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm Running Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "    __  _________ _   ____  ______    \r\n",
      "   /  |/  /  _/ /| | / / / / / __/    \r\n",
      "  / /|_/ // // /_| |/ / /_/ /\\ \\    \r\n",
      " /_/  /_/___/____/___/\\____/___/     \r\n",
      "\r\n",
      "Welcome to use Milvus!\r\n",
      "Milvus Release version: v1.1.0, built at 2021-05-06 14:50.43, with OpenBLAS library.\r\n",
      "You are using Milvus CPU edition\r\n",
      "Last commit id: 5e559cd7918297bcdb55985b80567cb6278074dd\r\n",
      "\r\n",
      "Loading configuration from: /var/lib/milvus/conf/server_config.yaml\r\n",
      "WARNNING: You are using SQLite as the meta data management, which can't be used in production. Please change it to MySQL!\r\n",
      "Supported CPU instruction sets: avx2, sse4_2\r\n",
      "FAISS hook AVX2\r\n",
      "Milvus server started successfully!\r\n"
     ]
    }
   ],
   "source": [
    "! docker logs milvus_cpu_1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-24 03:47:24.245 UTC [1] LOG:  starting PostgreSQL 13.3 (Debian 13.3-1.pgdg100+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 8.3.0-6) 8.3.0, 64-bit\r\n",
      "2021-05-24 03:47:24.245 UTC [1] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\r\n",
      "2021-05-24 03:47:24.245 UTC [1] LOG:  listening on IPv6 address \"::\", port 5432\r\n",
      "2021-05-24 03:47:24.252 UTC [1] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\r\n",
      "2021-05-24 03:47:24.259 UTC [67] LOG:  database system was shut down at 2021-05-24 03:47:24 UTC\r\n",
      "2021-05-24 03:47:24.265 UTC [1] LOG:  database system is ready to accept connections\r\n"
     ]
    }
   ],
   "source": [
    "! docker logs postgres --tail 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Servers\n",
    "We first start off by connecting to the servers. In this case the docker containers are running on localhost and the ports are the default ports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connectings to Milvus, BERT and Postgresql\n",
    "import milvus\n",
    "import psycopg2\n",
    "\n",
    "milv = milvus.Milvus(host='localhost', port='19533')\n",
    "conn = psycopg2.connect(host='localhost', port='5432', user='postgres', password='postgres')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Collection and Setting Index\n",
    "#### 1. Creating the Collection    \n",
    "A collection in Milvus is similar to a table in a relational database, and is used for storing all the vectors.  \n",
    "We need to specify the parameters `collection_name`, `dimension`, `index_file_size`, and `metric_type` when creating it. In this case we are storing 768-dimensional vectors and using the Inner product distance.\n",
    "Our data segments are also set to the default 1024MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status(code=0, message='Create collection successfully!')\n"
     ]
    }
   ],
   "source": [
    "TABLE_NAME = 'title_text_2'\n",
    "\n",
    "#Deleting previouslny stored table for clean run\n",
    "milv.drop_collection(TABLE_NAME)\n",
    "\n",
    "\n",
    "collection_param = {\n",
    "            'collection_name': TABLE_NAME,\n",
    "            'dimension': 768,\n",
    "            'index_file_size': 1024,  \n",
    "            'metric_type': milvus.MetricType.IP \n",
    "            }\n",
    "\n",
    "status = milv.create_collection(collection_param)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Setting an Index\n",
    "After creating the collection we want to assign it an index type. This can be done before or after inserting the data. When done before, indexes will be made as data comes in and fills the data segments. In this example we are using IVF_SQ8 which requires the 'nlist' parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status(code=0, message='Build index successfully!')\n"
     ]
    }
   ],
   "source": [
    "param = {'nlist': 16384}\n",
    "status = milv.create_index(TABLE_NAME, milvus.IndexType.IVF_SQ8, param)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Table in Postgres  \n",
    "PostgresSQL will be used to store Milvus ID and its corresponding title and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create postgres table successfully!\n"
     ]
    }
   ],
   "source": [
    "#Deleting previouslny stored table for clean run\n",
    "drop_table = \"DROP TABLE IF EXISTS \" + TABLE_NAME\n",
    "cursor.execute(drop_table)\n",
    "conn.commit()\n",
    "\n",
    "try:\n",
    "    sql = \"CREATE TABLE if not exists \" + TABLE_NAME + \" (ids bigint, title text, text text);\"\n",
    "    cursor.execute(sql)\n",
    "    conn.commit()\n",
    "    print(\"create postgres table successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"can't create a postgres table: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing and Storing the News Data\n",
    "#### 1. Generating Embeddings\n",
    "In this example we are using the sentence_transformer library  to encode the sentence into vectors. This library uses a modified BERT model to generate the embeddings, and in this example we are using a model pretrained using Microsoft's `mpnet`. More info can be found [here](https://www.sbert.net/docs/pretrained_models.html#sentence-embedding-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 1.2.0, however, your version is 1.1.1. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "model = SentenceTransformer('paraphrase-mpnet-base-v2')\n",
    "# Get questions and answers.\n",
    "data = pd.read_csv('data/example.csv')\n",
    "title_data = data['title'].tolist()\n",
    "text_data = data['text'].tolist()\n",
    "\n",
    "sentence_embeddings = model.encode(title_data)\n",
    "sentence_embeddings = normalize(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Inserting Vectors into Milvus\n",
    "Since this example dataset contains only 100 vectors, we are inserting all of them as one batch insert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status(code=0, message='Add vectors successfully!')\n"
     ]
    }
   ],
   "source": [
    "status, ids = milv.insert(collection_name=TABLE_NAME, records=sentence_embeddings)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Inserting IDs and Title-text into PostgreSQL\n",
    "In order to transfer the data into Postgres, we are creating a new file that combines all the data into a readable format. Once created, we pass this file into the Postgress server through STDIN due to the Postgres container not having access to the file locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted into Postgress Sucessfully!\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "def record_temp_csv(fname, ids, title, text):\n",
    "    with open(fname,'w') as f:\n",
    "        for i in range(len(ids)):\n",
    "            line = str(ids[i]) + \"|\" + title[i] + \"|\" + text[i] + \"\\n\"\n",
    "            f.write(line)\n",
    "\n",
    "def copy_data_to_pg(table_name, fname, conn, cur):\n",
    "    fname = os.path.join(os.getcwd(),fname)\n",
    "    try:\n",
    "        sql = \"COPY \" + table_name + \" FROM STDIN DELIMITER '|' CSV HEADER\"\n",
    "        cursor.copy_expert(sql, open(fname, \"r\"))\n",
    "        conn.commit()\n",
    "        print(\"Inserted into Postgress Sucessfully!\")\n",
    "    except Exception as e:\n",
    "        print(\"Copy Data into Postgress failed: \", e)\n",
    "        \n",
    "DATA_WITH_IDS = 'data/test.csv'   \n",
    "\n",
    "record_temp_csv(DATA_WITH_IDS, ids, title_data, text_data)\n",
    "copy_data_to_pg(TABLE_NAME, DATA_WITH_IDS, conn, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search\n",
    "#### 1. Processing Query\n",
    "When searching for a question, we first put the question through the same model to generate an embedding. Then with that embedding vector we  can search for similar embeddings in Milvus.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status(code=0, message='Search vectors successfully!')\n"
     ]
    }
   ],
   "source": [
    "SEARCH_PARAM = {'nprobe': 64}\n",
    "\n",
    "query_vec = []\n",
    "\n",
    "title = \"Loosing the War on Terrorism\"\n",
    "\n",
    "query_embeddings = []\n",
    "embed = model.encode(title)\n",
    "embed = embed.reshape(1,-1)\n",
    "embed = normalize(embed)\n",
    "query_embeddings = embed.tolist()\n",
    "\n",
    "\n",
    "status, results = milv.search(collection_name=TABLE_NAME, query_records=query_embeddings, top_k=9, params=SEARCH_PARAM)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Getting the Similar Titles\n",
    "There may not have titles that are similar to the given one. So we can set a threshold value, here we use 0.5, and when the most similar distance retrieved is less than this value, a hint that the system doesn't include the relevant question is returned. We then use the result ID's to pull out the similar titles from the Postgres server and print them with their corresponding similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are similar questions in the database, here are the closest matches: \n",
      "('Loosing the War on Terrorism', 0.9999999403953552)\n",
      "('Politics an Afterthought Amid Hurricane  ', 0.294342577457428)\n",
      "('Kerry-Kerrey Confusion Trips Up Campaign  ', 0.2923681437969208)\n",
      "('News: Sluggish movement on power grid cyber security', 0.2759988009929657)\n",
      "('Promoting a Shared Vision', 0.2651735246181488)\n",
      "('U.S. Brokers Cease-fire in Western Afghanistan', 0.2630968689918518)\n",
      "('On front line of AIDS in Russia', 0.2530452609062195)\n",
      "('Fresh Fighting Shatters Short-Lived Ceasefire Deal', 0.23172177374362946)\n",
      "('Flop in the ninth inning sinks Jays', 0.21579097211360931)\n"
     ]
    }
   ],
   "source": [
    "similar_titles = []\n",
    "\n",
    "if results[0][0].distance < 0.5:\n",
    "    print(\"There are no similar questions in the database, here are the closest matches:\")\n",
    "else:\n",
    "    print(\"There are similar questions in the database, here are the closest matches: \")\n",
    "    \n",
    "for result in results[0]:\n",
    "    sql = \"select title from \" + TABLE_NAME + \" where ids = \" + str(result.id) + \";\"\n",
    "    cursor.execute(sql)\n",
    "    rows=cursor.fetchall()\n",
    "    if len(rows):\n",
    "        similar_titles.append((rows[0][0], result.distance))\n",
    "        print((rows[0][0], result.distance))\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Get the text\n",
    "After getting a list of similar titles, choose the one that you feel is closest to yours. Then you can use that title to find the corresponding text in Postgres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Loosing the War on Terrorism\n",
      "Text:\n",
      " Sven Jaschan, self-confessed author of the Netsky and Sasser viruses, is responsible for 70 percent of virus infections in 2004, according to a six-month virus roundup published Wednesday by antivirus company Sophos.  The 18-year-old Jaschan was taken into custody in Germany in May by police who said he had admitted programming both the Netsky and Sasser worms, something experts at Microsoft confirmed. (A Microsoft antivirus reward program led to the teenager's arrest.) During the five months preceding Jaschan's capture, there were at least 25 variants of Netsky and one of the port-scanning network worm Sasser.  Graham Cluley, senior technology consultant at Sophos, said it was staggeri   \n"
     ]
    }
   ],
   "source": [
    "sql = \"select text from \" + TABLE_NAME + \" where title = '\" + similar_titles[0][0] + \"';\"\n",
    "cursor.execute(sql)\n",
    "rows=cursor.fetchall()\n",
    "print(\"Title:\")\n",
    "print(title)\n",
    "print(\"Text:\")\n",
    "print(rows[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
